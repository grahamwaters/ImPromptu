[
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "markdown",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "markdown",
        "description": "markdown",
        "detail": "markdown",
        "documentation": {}
    },
    {
        "label": "black",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "black",
        "description": "black",
        "detail": "black",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm.auto",
        "description": "tqdm.auto",
        "isExtraImport": true,
        "detail": "tqdm.auto",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "combine_readme",
        "kind": 2,
        "importPath": "generate_readme",
        "description": "generate_readme",
        "peekOfCode": "def combine_readme(top, middle, bottom):\n    # Create dynamic badges for middle section\n    badges = []\n    # the files in the specific_topics folder are the topics\n    badge_count = len(os.listdir(\"specific_topics\"))\n    for i in tqdm(range(badge_count)):\n        badge_color = random.choice([\"green\", \"orange\", \"red\", \"blue\", \"yellow\", \"pink\", \"purple\", \"grey\", \"blue\", \"blueviolet\",\"brown\", \"darkgrey\", \"lightgreen\", \"darkgreen\", \"lightblue\", \"darkblue\", \"lightyellow\", \"darkyellow\", \"lightpink\", \"darkpink\", \"lightpurple\", \"darkpurple\", \"lightbrown\", \"darkbrown\", \"lightblack\", \"darkblack\", \"lightwhite\", \"darkwhite\", \"lightred\", \"darkred\", \"lightorange\", \"darkorange\"])\n        badge_text = f\"Badge_{i + 1}\"\n        # get the name of the file\n        badge_filename = os.listdir(\"specific_topics\")[i] # get the name of the file",
        "detail": "generate_readme",
        "documentation": {}
    },
    {
        "label": "combined_readme",
        "kind": 5,
        "importPath": "generate_readme",
        "description": "generate_readme",
        "peekOfCode": "combined_readme = combine_readme(top, middle, bottom)\n# Write the combined README to the root directory\nwith open(\"README.md\", \"w\") as file:\n    file.write(combined_readme)",
        "detail": "generate_readme",
        "documentation": {}
    },
    {
        "label": "make_a_prompt",
        "kind": 2,
        "importPath": "prompt_generator",
        "description": "prompt_generator",
        "peekOfCode": "def make_a_prompt():\n    \"\"\"\n        This function, make_a_prompt, guides the user through the process of creating a prompt for the chatGPT model.\n        It prompts the user to input various pieces of information, such as the type of bot they would like the model to be,\n        the problem the prompt is trying to solve, and the constraints and requirements the prompt must follow.\n        It then uses this information to craft an action and outcome.\n        #NOTE: currently the inputs are commented out so that the function can be run without user input. see the #! comments for the inputs.\n    \"\"\"\n    input_mode = False # set to true to use the input mode, false to use the example mode\n    print(\"Welcome to the prompt generator!\")",
        "detail": "prompt_generator",
        "documentation": {}
    },
    {
        "label": "generate_readme",
        "kind": 2,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "def generate_readme(industries, readme_file):\n    with open(readme_file, \"w\") as f:\n        f.write(\"# chatGPT Prompts For Everyone! *Domain Agnostic Prompts for Savvy Professionals* \\n## Industries List\\n\\n\")\n        for industry in industries:\n            f.write(f\"- [{industry}](./industries/{industry}.md)\\n\")\n# generate readme\n#!generate_readme(industries, \"README.md\")\n# create a folder for all of the industries\n#// os.remove(\"industries\")\n#!os.mkdir(\"industries\")",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "generate_readme_topics",
        "kind": 2,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "def generate_readme_topics(industries, readme_file, subfiles):\n    # Create the specific_topics folder if it doesn't already exist\n    if not os.path.exists(\"specific_topics\"):\n        os.makedirs(\"specific_topics\")\n    with open(readme_file, \"w\") as f:\n        f.write(\"# Industry List\\n\")\n        for industry in industries:\n            # Create subfiles for each programming language and technical program\n            for subfile in subfiles:\n                subfile_path = os.path.join(\"specific_topics\", f\"{subfile}.md\")",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "industries",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "industries = [\"Software Engineering\", \"UX Design\", \"Web Development\", \"Literature\", \"Art\", \"Music\", \"Film\", \"Photography\", \"Architecture\", \"Interior Design\", \"Graphic Design\", \"Fashion\", \"Product Design\", \"Industrial Design\", \"Game Design\", \"Animation\", \"Videography\", \"Journalism\", \"Advertising\", \"Marketing\", \"Public Relations\", \"Business\", \"Economics\", \"Finance\", \"Law\", \"Politics\", \"Psychology\", \"Sociology\", \"History\", \"Philosophy\", \"Religion\", \"Education\", \"Medicine\", \"Health\", \"Nutrition\", \"Fitness\", \"Sports\", \"Travel\", \"Food\", \"Cooking\", \"Crafts\", \"Home Improvement\", \"Gardening\", \"Pets\", \"Parenting\", \"Beauty\", \"Lifestyle\", \"Science\", \"Technology\", \"Mathematics\", \"Engineering\", \"Astronomy\", \"Chemistry\", \"Physics\", \"Biology\", \"Computer Science\", \"Data Science\", \"Robotics\", \"Entrepreneurship\", \"Personal Development\", \"Productivity\", \"Self Improvement\", \"Career Development\", \"Hobbies\", \"Languages\", \"Other\"]\nindustries = sorted(industries)\nindustries = [industry.lower().replace(\" \", \"_\") for industry in industries]\ndef generate_readme(industries, readme_file):\n    with open(readme_file, \"w\") as f:\n        f.write(\"# chatGPT Prompts For Everyone! *Domain Agnostic Prompts for Savvy Professionals* \\n## Industries List\\n\\n\")\n        for industry in industries:\n            f.write(f\"- [{industry}](./industries/{industry}.md)\\n\")\n# generate readme\n#!generate_readme(industries, \"README.md\")",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "industries",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "industries = sorted(industries)\nindustries = [industry.lower().replace(\" \", \"_\") for industry in industries]\ndef generate_readme(industries, readme_file):\n    with open(readme_file, \"w\") as f:\n        f.write(\"# chatGPT Prompts For Everyone! *Domain Agnostic Prompts for Savvy Professionals* \\n## Industries List\\n\\n\")\n        for industry in industries:\n            f.write(f\"- [{industry}](./industries/{industry}.md)\\n\")\n# generate readme\n#!generate_readme(industries, \"README.md\")\n# create a folder for all of the industries",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "industries",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "industries = [industry.lower().replace(\" \", \"_\") for industry in industries]\ndef generate_readme(industries, readme_file):\n    with open(readme_file, \"w\") as f:\n        f.write(\"# chatGPT Prompts For Everyone! *Domain Agnostic Prompts for Savvy Professionals* \\n## Industries List\\n\\n\")\n        for industry in industries:\n            f.write(f\"- [{industry}](./industries/{industry}.md)\\n\")\n# generate readme\n#!generate_readme(industries, \"README.md\")\n# create a folder for all of the industries\n#// os.remove(\"industries\")",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "subfiles",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "subfiles = [\"JavaScript\", \"Python\", \"C#\", \"Java\", \"C++\", \"C\", \"Ruby\", \"Swift\", \"PHP\", \"Go\", \"Rust\", \"Kotlin\", \"TypeScript\", \"generator\", \"mathematician\",\"physicist\",\"professor\",\"R\", \"Scala\", \"Perl\", \"Shell\", \"Objective-C\", \"SQL\", \"Excel Formulas\", \"Visio\", \"VBA\", \"Power BI\", \"SAS\",\n            \"Tableau\", \"QlikView\", \"D3.js\", \"Data Visualization\", \"Data Analysis\", \"Machine Learning\", \"Deep Learning\", \"algorithm\",\n            \"Computer Vision\", \"Natural Language Processing\", \"Data Science\", \"Big Data\", \"Data Engineering\", \"DevOps\",\n            \"Cloud Computing\", \"Docker\", \"Kubernetes\", \"AWS\", \"Azure\", \"Google Cloud\", \"Linux\", \"Windows\", \"macOS\", \"Detector\", \"Book\",\n            \"iOS\", \"Android\", \"Pointers in Computer Science\", \"Algorithms\", \"Data Structures\", \"Operating Systems\", \"Game\", \"Advice\", \"\"\n            \"Networking\", \"Security\", \"Cryptography\", \"Blockchain\", \"IoT\", \"AR/VR\", \"Computer Graphics\", \"Computer Architecture\",\n            \"Compilers\", \"Assembler\", \"Debugging\", \"Testing\", \"Agile\", \"Scrum\", \"Kanban\", \"Lean\", \"Waterfall\", \"PMP\", \"translate\",\n            \"PRINCE2\", \"ITIL\", \"COBIT\", \"TOGAF\", \"SOA\", \"Microservices\", \"Monolithic\", \"Functional Programming\", \"diet\", \"coach\",\"english\", \"Regex\", \"Full Stack Development\", \"Front End Development\", \"Back End Development\", \"Mobile Development\", \"Desktop Development\",\n            \"Object-Oriented Programming\", \"Procedural Programming\", \"Event-Driven Programming\", \"Concurrent Programming\", \"Creator\",\n            \"Distributed Systems\", \"Parallel Computing\", \"High-Performance Computing\", \"Embedded Systems\", \"Firmware\", \"Post\"]",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "subfiles",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "subfiles = sorted(subfiles)\nsubfiles = [sub.replace(\" \", \"_\").replace('.','_').replace('/','').lower() for sub in subfiles]\n# remove duplicates\nsubfiles = list(dict.fromkeys(subfiles))\ndef generate_readme_topics(industries, readme_file, subfiles):\n    # Create the specific_topics folder if it doesn't already exist\n    if not os.path.exists(\"specific_topics\"):\n        os.makedirs(\"specific_topics\")\n    with open(readme_file, \"w\") as f:\n        f.write(\"# Industry List\\n\")",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "subfiles",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "subfiles = [sub.replace(\" \", \"_\").replace('.','_').replace('/','').lower() for sub in subfiles]\n# remove duplicates\nsubfiles = list(dict.fromkeys(subfiles))\ndef generate_readme_topics(industries, readme_file, subfiles):\n    # Create the specific_topics folder if it doesn't already exist\n    if not os.path.exists(\"specific_topics\"):\n        os.makedirs(\"specific_topics\")\n    with open(readme_file, \"w\") as f:\n        f.write(\"# Industry List\\n\")\n        for industry in industries:",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "subfiles",
        "kind": 5,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "subfiles = list(dict.fromkeys(subfiles))\ndef generate_readme_topics(industries, readme_file, subfiles):\n    # Create the specific_topics folder if it doesn't already exist\n    if not os.path.exists(\"specific_topics\"):\n        os.makedirs(\"specific_topics\")\n    with open(readme_file, \"w\") as f:\n        f.write(\"# Industry List\\n\")\n        for industry in industries:\n            # Create subfiles for each programming language and technical program\n            for subfile in subfiles:",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "create_prompts_csv",
        "kind": 2,
        "importPath": "topic_sorting",
        "description": "topic_sorting",
        "peekOfCode": "def create_prompts_csv(markdown_file):\n    prompts_df = pd.DataFrame(columns=[\"topic\", \"prompt\", \"contributor\", \"link\"])\n    # read the markdown file, extract the prompts, and write them to a csv file\n    with open(markdown_file, \"r\") as f:\n        markdown_text = f.read()\n    # the first edge is the first \"##\" and the second edge is the next \"##\" or the end of the file\n    sections = re.split(r\"## \", markdown_text)[\n        1:\n    ]  # split the markdown text into sections\n    prompts = []",
        "detail": "topic_sorting",
        "documentation": {}
    },
    {
        "label": "extract_prompts",
        "kind": 2,
        "importPath": "topic_sorting",
        "description": "topic_sorting",
        "peekOfCode": "def extract_prompts(markdown_file, TOPICS):\n    # assert that the markdown file exists, and that the topics are a list of strings.\n    assert os.path.exists(markdown_file), \"The markdown file does not exist.\"\n    assert isinstance(TOPICS, list), \"The topics must be a list of strings.\"\n    with open(markdown_file, \"r\") as f:\n        markdown_text = f.read()\n    for topic in tqdm(TOPICS, total=len(TOPICS)):\n        # write the prompts to the file \"topic.md\" in the \"specific_topics\" folder\n        with open(f\"specific_topics/{topic.replace(' ', '_')}.md\", \"w\") as f:\n            f.write(\"\\n\".join(topic_prompts))",
        "detail": "topic_sorting",
        "documentation": {}
    },
    {
        "label": "populate_files_from_csv",
        "kind": 2,
        "importPath": "topic_sorting",
        "description": "topic_sorting",
        "peekOfCode": "def populate_files_from_csv():\n    # code to read csv file and create prompts_df here\n    # make sure the topics are in the TOPICS list\n    for topic_string in tqdm(TOPICS, total=len(TOPICS)):\n        with open(\n            f\"specific_topics/{str(topic_string).replace(' ', '_')}.md\", \"a+\"\n        ) as f:  # open the file in append mode, create it only if it doesn't exist\n            # convert the topic_string topic back to a normal word (e.g. \"specific_topic\" -> \"specific topic\")\n            topic = topic_string.replace(\"_\", \" \")\n            # define a small data frame with only the rows where the topic matches the topic_string",
        "detail": "topic_sorting",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "topic_sorting",
        "description": "topic_sorting",
        "peekOfCode": "def main():\n    create_prompts_csv(\"readme_other.md\")\n    # extract_prompts(\"readme_other.md\", TOPICS)\n    #!populate_files_from_csv() # populate the markdown files in the \"specific_topics\" folder with the prompts from the csv file\nif __name__ == \"__main__\":\n    main()",
        "detail": "topic_sorting",
        "documentation": {}
    },
    {
        "label": "TOPICS",
        "kind": 5,
        "importPath": "topic_sorting",
        "description": "topic_sorting",
        "peekOfCode": "TOPICS = os.listdir(\n    \"specific_topics\"\n)  # get the list of file names in the \"specific_topics\" folder\nTOPICS = [\n    topic.replace(\".md\", \"\") for topic in TOPICS\n]  # remove the \".md\" from the file names\nTOPICS = [\n    topic.replace(\"_\", \" \") for topic in TOPICS\n]  # replace the underscores with spaces\nprompts_df = pd.read_csv(\"prompts.csv\")",
        "detail": "topic_sorting",
        "documentation": {}
    },
    {
        "label": "TOPICS",
        "kind": 5,
        "importPath": "topic_sorting",
        "description": "topic_sorting",
        "peekOfCode": "TOPICS = [\n    topic.replace(\".md\", \"\") for topic in TOPICS\n]  # remove the \".md\" from the file names\nTOPICS = [\n    topic.replace(\"_\", \" \") for topic in TOPICS\n]  # replace the underscores with spaces\nprompts_df = pd.read_csv(\"prompts.csv\")\nimport numpy as np\ndef create_prompts_csv(markdown_file):\n    prompts_df = pd.DataFrame(columns=[\"topic\", \"prompt\", \"contributor\", \"link\"])",
        "detail": "topic_sorting",
        "documentation": {}
    },
    {
        "label": "TOPICS",
        "kind": 5,
        "importPath": "topic_sorting",
        "description": "topic_sorting",
        "peekOfCode": "TOPICS = [\n    topic.replace(\"_\", \" \") for topic in TOPICS\n]  # replace the underscores with spaces\nprompts_df = pd.read_csv(\"prompts.csv\")\nimport numpy as np\ndef create_prompts_csv(markdown_file):\n    prompts_df = pd.DataFrame(columns=[\"topic\", \"prompt\", \"contributor\", \"link\"])\n    # read the markdown file, extract the prompts, and write them to a csv file\n    with open(markdown_file, \"r\") as f:\n        markdown_text = f.read()",
        "detail": "topic_sorting",
        "documentation": {}
    },
    {
        "label": "prompts_df",
        "kind": 5,
        "importPath": "topic_sorting",
        "description": "topic_sorting",
        "peekOfCode": "prompts_df = pd.read_csv(\"prompts.csv\")\nimport numpy as np\ndef create_prompts_csv(markdown_file):\n    prompts_df = pd.DataFrame(columns=[\"topic\", \"prompt\", \"contributor\", \"link\"])\n    # read the markdown file, extract the prompts, and write them to a csv file\n    with open(markdown_file, \"r\") as f:\n        markdown_text = f.read()\n    # the first edge is the first \"##\" and the second edge is the next \"##\" or the end of the file\n    sections = re.split(r\"## \", markdown_text)[\n        1:",
        "detail": "topic_sorting",
        "documentation": {}
    },
    {
        "label": "prompts_df",
        "kind": 5,
        "importPath": "topic_sorting",
        "description": "topic_sorting",
        "peekOfCode": "prompts_df = pd.read_csv(\"prompts.csv\")\n# Step 2: Populate the markdown files with the prompts from the csv file\ndef main():\n    create_prompts_csv(\"readme_other.md\")\n    # extract_prompts(\"readme_other.md\", TOPICS)\n    #!populate_files_from_csv() # populate the markdown files in the \"specific_topics\" folder with the prompts from the csv file\nif __name__ == \"__main__\":\n    main()",
        "detail": "topic_sorting",
        "documentation": {}
    }
]